{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9eb316d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 inf\n",
      "20 nan\n",
      "30 nan\n",
      "40 nan\n",
      "50 nan\n",
      "60 nan\n",
      "70 nan\n",
      "80 nan\n",
      "90 nan\n",
      "100 nan\n"
     ]
    }
   ],
   "source": [
    "# 3.1 딥러닝의 원리\n",
    "# 퍼셉트론 : 뉴런과 같은 기본역할\n",
    "\n",
    "#3.1.2 심층 신경망\n",
    "\n",
    "from sklearn import datasets\n",
    "import torch\n",
    "import torch.nn as nn # 신경망을 구현하는데 필요한 기능 구현\n",
    "import torch.optim as optim #옵티마이저 구현\n",
    "\n",
    "dataset = datasets.load_boston()\n",
    "X, y = dataset['data'], dataset['target']\n",
    "\n",
    "X = torch.FloatTensor(X)\n",
    "y = torch.FloatTensor(y).unsqueeze(-1)\n",
    "\n",
    "X = (X - torch.mean(X) / torch.std(X)) #데이터 범위 조정을 위해 표준화 적용\n",
    "model = nn.Linear(13, 1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 손실함수로 모델이 추론한 타깃과 실제 타깃 사이의 차이, 오차를 계산\n",
    "# 미분으로 손실 함수의 기울기를 계산, 가중치를 어떻게 수정 오차가 줄어드는지 파악\n",
    "# => '에포크(epoch)'\n",
    "\n",
    "def train(model, criterion, optimizer, X, y):\n",
    "    optimizer.zero_grad() # 기울기 초기화\n",
    "    hypothesis = model(X) # 모델을 사용해 타깃을 추론\n",
    "    loss = criterion(hypothesis, y) # 오차를 계산\n",
    "    loss.backward() # 기울기 계산\n",
    "    optimizer.step() # 경사 하강법으로 가중치를 수정\n",
    "    return loss.item() #에포크 오차 반환\n",
    "\n",
    "n_epochs = 100\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    loss = train(model, criterion, optimizer, X, y)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(epoch, loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7812f77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 62.741653\n",
      "epoch: 20, loss: 62.741653\n",
      "epoch: 30, loss: 62.741653\n",
      "epoch: 40, loss: 62.741653\n",
      "epoch: 50, loss: 62.741653\n",
      "epoch: 60, loss: 62.741653\n",
      "epoch: 70, loss: 62.741653\n",
      "epoch: 80, loss: 62.741653\n",
      "epoch: 90, loss: 62.741653\n",
      "epoch: 100, loss: 62.741653\n",
      "tensor(0.3726)\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀 : 선형회귀에 시그모이드 함수를 추가 , 이진 크로스 엔트로피 손실 함수를 사용\n",
    "\n",
    "from sklearn import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "dataset = datasets.load_breast_cancer()\n",
    "\n",
    "X, y = dataset['data'], dataset['target']\n",
    "\n",
    "X = torch.FloatTensor(X)\n",
    "y = torch.FloatTensor(y).view(-1, 1)\n",
    "\n",
    "X = (X - torch.mean(X) / torch.std(X)) # 표준화 적용\n",
    "\n",
    "model = nn.Sequential(nn.Linear(30, 1),nn.Sigmoid())\n",
    "criterion = nn.BCELoss() # 이진 크로스 엔트로피 손실 함수 객체를 생성\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1) # 확율적 경사 하강법 옵티마이저 객체\n",
    "\n",
    "n_epochs = 100\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    loss = train(model, criterion, optimizer, X, y)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch: {}, loss: {:4f}'.format(epoch, loss))\n",
    "\n",
    "\n",
    "y_predicted = (model(X) >= 0.5).float()\n",
    "\n",
    "score = (y_predicted==y).float().mean()\n",
    "print(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59bec8cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearRegression' object has no attribute 'linear'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m         out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(X) \u001b[39m# 생성자에서 만든 타깃으 추론하고 반환\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m---> 11\u001b[0m model \u001b[39m=\u001b[39m LinearRegression(\u001b[39m13\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m, in \u001b[0;36mLinearRegression.__init__\u001b[1;34m(self, num_features)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, num_features):\n\u001b[0;32m      3\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m() \u001b[39m# 부모의 생성자를 호출\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear \u001b[39m==\u001b[39m nn\u001b[39m.\u001b[39mLinear(num_features, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1267\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1268\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1269\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1270\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LinearRegression' object has no attribute 'linear'"
     ]
    }
   ],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__() # 부모의 생성자를 호출\n",
    "        self.linear == nn.Linear(num_features, 1) #num_features 개의 특성을 입력받는 선형 모델 객체를 생성\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = self.linear(X) # 생성자에서 만든 타깃으 추론하고 반환\n",
    "        return out\n",
    "\n",
    "\n",
    "model = LinearRegression(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b862ee4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NeuralNetwork' object has no attribute 'paramters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m model \u001b[39m=\u001b[39m NeuralNetwork(\u001b[39m30\u001b[39m)\n\u001b[0;32m     39\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCELoss() \u001b[39m# 이진 크로스 엔트로피 손실 함수 객체를 생성\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39;49mparamters(), lr\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m) \u001b[39m# 확률적 경사 하강법 옵티마이저 객체를 생성\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(model, criterion, optimizer, loader):\n\u001b[0;32m     44\u001b[0m     epoch_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1267\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1268\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1269\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1270\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NeuralNetwork' object has no attribute 'paramters'"
     ]
    }
   ],
   "source": [
    "# 3.2.4 배치학습\n",
    "\n",
    "\n",
    "#데이터를 조금씩 나눠서 처리하는 배치(batch)라는 개념 등장\n",
    "\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "dataset = datasets.load_breast_cancer()\n",
    "X, y = dataset['data'], dataset['target']\n",
    "X = torch.FloatTensor(X)\n",
    "y = torch.FloatTensor(y).view(-1, 1)\n",
    "\n",
    "x = (X - torch.mean(X)) / torch.std(X)\n",
    "\n",
    "dset = TensorDataset(X, y)\n",
    "loader = DataLoader(dset, batch_size=256, shuffle = True) \n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__() # 상속받아 생성한 객체, 부모의 생성자를 호출\n",
    "        self.linear1 = nn.Linear(num_features, 4) # num_features개의 특성을 입력받는 은닉층 노드를 4개 생성\n",
    "        self.relu = nn.ReLU() # 렐루 함수 객체 생성\n",
    "        self.linear2 = nn.Linear(4, 1) #4개의 값을 입력받는 출력층 노드 1개를 생성\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = self.linear1(X)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNetwork(30)\n",
    "criterion = nn.BCELoss() # 이진 크로스 엔트로피 손실 함수 객체를 생성\n",
    "optimizer = optim.SGD(model.paramters(), lr=0.1) # 확률적 경사 하강법 옵티마이저 객체를 생성\n",
    "\n",
    "def train(model, criterion, optimizer, loader):\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X_batch)\n",
    "        loss = criterion(hypothesis, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "\n",
    "n_epochs = 100\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    loss = train(model, criterion, optimizer, loader)\n",
    "\n",
    "    if epoch % 10 ==0:\n",
    "        print(epoch, loss)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdb19579",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 86\u001b[0m\n\u001b[0;32m     83\u001b[0m n_epochs \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[0;32m     85\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m---> 86\u001b[0m     loss, acc \u001b[39m=\u001b[39m train(model, criterion, optimizer, train_loader)\n\u001b[0;32m     87\u001b[0m     test_loss, test_acc \u001b[39m=\u001b[39m evaluate(model, criterion, test_loader)\n\u001b[0;32m     89\u001b[0m     \u001b[39mprint\u001b[39m(epoch, loss, acc, test_loss, test_acc)\n",
      "Cell \u001b[1;32mIn[18], line 53\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, criterion, optimizer, loader)\u001b[0m\n\u001b[0;32m     50\u001b[0m epoch_acc \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[39mfor\u001b[39;00m X_batch, y_batch \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m---> 53\u001b[0m     X_batch, y_batch \u001b[39m=\u001b[39m X_batch\u001b[39m.\u001b[39mto(device), y_batch(device)\n\u001b[0;32m     54\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     55\u001b[0m     hypothesis \u001b[39m=\u001b[39m model(X_batch)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "# 3.3 전결합 신경망\n",
    "\n",
    "# 3.3.1 손글씨 이미지 분류하기\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_dataset = datasets.MNIST('./', train=True, download=True)\n",
    "test_dataset = datasets.MNIST('./', train=False, download=True)\n",
    "\n",
    "X_train, y_train = train_dataset.data / 255, train_dataset.targets\n",
    "X_test, y_test = test_dataset.data / 255, test_dataset.targets \n",
    "\n",
    "X_train, X_test = X_train.view(-1, 784), X_test.view(-1, 784)\n",
    "\n",
    "train_dset = TensorDataset(X_train, y_train)\n",
    "test_dset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(train_dset, batch_size=32, shuffle=True)\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.hidden_layer1 = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.hidden_layer2 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.output_layer = nn.Linear(128, 10)\n",
    "\n",
    "def forward(self, X):\n",
    "    out = self.hidden_layer1(X)\n",
    "    out = self.hidden_layer2(out)\n",
    "    out = self.output_layer(out)\n",
    "    return out\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # 그래픽 카드 사용이 가능할 경우 그래픽 카드로 연산하도록 설정\n",
    "model = DNN(784).to(device) # 784 개의 값을 입력받는 로지스틱 회귀 모델 객체를 생성\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer  = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "def train(model, criterion, optimizer, loader):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch(device)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X_batch)\n",
    "        loss = criterion(hypothesis, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_predicted = torch.argmax(hypothesis, 1)\n",
    "        acc = (y_predicted == y_batch).float().mean()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)\n",
    "\n",
    "def evaluate(model, criterion, loader):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            hypothesis = model(X_batch)\n",
    "            loss = criterion(hypothesis, y_batch)\n",
    "            y_predicted = torch.argmax(hypothesis, 1)\n",
    "            acc = (y_predicted == y_batch).foat().mean()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / len(loader), epoch_acc /len(loader)\n",
    "\n",
    "\n",
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    loss, acc = train(model, criterion, optimizer, train_loader)\n",
    "    test_loss, test_acc = evaluate(model, criterion, test_loader)\n",
    "\n",
    "    print(epoch, loss, acc, test_loss, test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aea9942",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "MNIST",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_bunch.py:35\u001b[0m, in \u001b[0;36mBunch.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[key]\n\u001b[0;32m     36\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'MNIST'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 12\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39moptim\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m train_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mMNIST(\u001b[39m'\u001b[39m\u001b[39m./\u001b[39m\u001b[39m'\u001b[39m, train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m test_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mMNIST(\u001b[39m'\u001b[39m\u001b[39m./\u001b[39m\u001b[39m'\u001b[39m, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m X_train, y_train \u001b[39m=\u001b[39m train_dataset\u001b[39m.\u001b[39mdata \u001b[39m/\u001b[39m \u001b[39m255\u001b[39m, train_dataset\u001b[39m.\u001b[39mtargets\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_bunch.py:37\u001b[0m, in \u001b[0;36mBunch.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[0;32m     36\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m---> 37\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(key)\n",
      "\u001b[1;31mAttributeError\u001b[0m: MNIST"
     ]
    }
   ],
   "source": [
    "# 합성곱 신경망\n",
    "# 3.4.1 합성곱 신경망 개념\n",
    "\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = dataset.MNIST('./', train=True, download=True)\n",
    "test_dataset = dataset.MNIST('./', train=False, download=True)\n",
    "\n",
    "X_train, y_train = train_dataset.data / 255, train_dataset.targets\n",
    "X_test, y_test = test_dataset.data / 255, test_dataset.targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e911567b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "23f823caeccb1684f6bd50492b68bb5eab208de0408f39b2457c6a38c0e8e818"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
